{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "approximate-prague",
   "metadata": {
    "id": "approximate-prague",
    "tags": []
   },
   "source": [
    "# Node and Edge features\n",
    "This notebooks provide additional information about which geo-spatial features correspond to node feature matrix in TAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interesting-northwest",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "interesting-northwest",
    "outputId": "b1f0cb18-b289-4dbb-a843-86072b12b98a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSMnx version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "np.random.seed(17)\n",
    "print('OSMnx version:', ox.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33015908-3d47-4798-b91b-96f4f53585b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\", \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \"Minnesota\": \"MN\", \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\", \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\", \"New Mexico\": \"NM\", \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \"Ohio\": \"OH\", \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\", \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\", \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\", \"District of Columbia\": \"DC\", \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\", \"Northern Mariana Islands\": \"MP\", \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\", \"U.S. Virgin Islands\": \"VI\",\n",
    "}\n",
    "    \n",
    "# invert the dictionary\n",
    "us_abbrev_to_state = dict(map(reversed, us_state_to_abbrev.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4590c3e-7b23-4e96-a959-cdde004cb613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State null values: 0 \n",
      "City null values: 1632549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2845342, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/bing_crash_geocoded.csv')\n",
    "df.loc[df.City.isna(), 'City'] = df.loc[df.City.isna(), 'City_Old']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a05013-5a2b-4710-878d-922e73b94952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('datasets/v16_1k_city_ls.pkl', 'rb') as fp:\n",
    "    all_city_ls = pickle.load(fp)\n",
    "len(all_city_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef53f37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1952926, 23)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 = df[df.apply(lambda row: (row['City'], row['State']) in all_city_ls, axis=1)]\n",
    "# df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbd35289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Miami', 'Florida'),\n",
       " ('Los Angeles', 'California'),\n",
       " ('Orlando', 'Florida'),\n",
       " ('Dallas', 'Texas'),\n",
       " ('Houston', 'Texas'),\n",
       " ('New York', 'New York'),\n",
       " ('Charlotte', 'North Carolina'),\n",
       " ('San Diego', 'California'),\n",
       " ('Nashville', 'Tennessee'),\n",
       " ('Sacramento', 'California')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_city_ls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cf89c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current City: ('New York', 'New York')\n",
      "Node shape: (55292, 12) features: Index(['street_count', 'high_crossing', 'high_give_way',\n",
      "       'high_motorway_junction', 'high_nan', 'high_priority', 'high_stop',\n",
      "       'high_toll_gantry', 'high_traffic_signals',\n",
      "       'high_traffic_signals;crossing', 'high_turning_circle',\n",
      "       'high_turning_loop'],\n",
      "      dtype='object')\n",
      "Edge shape: (139463, 19) features: Index(['length', 'bridge', 'lanes', 'oneway_False', 'oneway_True',\n",
      "       'high_busway', 'high_living_street', 'high_motorway',\n",
      "       'high_motorway_link', 'high_primary', 'high_primary_link',\n",
      "       'high_residential', 'high_secondary', 'high_secondary_link',\n",
      "       'high_tertiary', 'high_tertiary_link', 'high_trunk', 'high_trunk_link',\n",
      "       'high_unclassified'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for i, e in enumerate(all_city_ls[5:6]):\n",
    "    print('Current City:', e)\n",
    "    df_city = df[(df.State == e[1]) & (df.City == e[0])]\n",
    "    df_city = df_city[['Severity','Start_Lat','Start_Lng','End_Lat','End_Lng','Start_Time','End_Time','osm_id']]\n",
    "    G_city = ox.graph_from_place({\"city\": e[0], \"state\": e[1]}, simplify=True, network_type='drive')\n",
    "    \n",
    "    nearest_nodes = ox.distance.nearest_nodes(G_city, df_city['Start_Lng'], df_city['Start_Lat'])\n",
    "    # Map OSM node to accident node? or delete node with no accident\n",
    "    if all(ele == nearest_nodes[0] for ele in nearest_nodes[:10]):\n",
    "        nearest_nodes_bug_check_ls.append(e)\n",
    "        print('WARNING: may have a nearest_nodes bug')\n",
    "    df_city['osmid'] = nearest_nodes\n",
    "    \n",
    "    gdf_nodes, gdf_edges = ox.graph_to_gdfs(G_city)\n",
    "    gdf_nodes['start_time'] = np.empty((len(gdf_nodes), 0)).tolist()  # Add time stamps\n",
    "    gdf_nodes['end_time'] = np.empty((len(gdf_nodes), 0)).tolist()    \n",
    "    for idx in gdf_nodes.index:\n",
    "        gdf_nodes.loc[idx, 'accident_cnt'] = df_city[df_city['osmid'] == idx]['Severity'].count()\n",
    "        gdf_nodes.loc[idx, 'severity'] = df_city[df_city['osmid'] == idx]['Severity'].mean()\n",
    "        gdf_nodes.at[idx, 'start_time'] += list(df_city[df_city['osmid'] == idx]['Start_Time'])\n",
    "        gdf_nodes.at[idx, 'end_time'] += list(df_city[df_city['osmid'] == idx]['End_Time'])       \n",
    "    gdf_nodes.severity.fillna(0, inplace=True)  # 0 denotes no accident\n",
    "        \n",
    "    le = LabelEncoder()\n",
    "    gdf_edges['highway'].fillna('nan', inplace=True)\n",
    "    try:\n",
    "        gdf_nodes['highway'].fillna('nan', inplace=True)\n",
    "        gdf_nodes = pd.concat([gdf_nodes, pd.get_dummies(gdf_nodes.highway, prefix='high')], axis=1)\n",
    "    except:\n",
    "        cities_no_highway_node_attr_ls.append(e)\n",
    "        continue\n",
    "    \n",
    "    # Some cells contain list values\n",
    "    for i in gdf_edges.index:\n",
    "        if type(gdf_edges.loc[i, 'highway']) is list:\n",
    "            gdf_edges.loc[i, 'highway'] = 'residential'\n",
    "        if type(gdf_edges.loc[i, 'oneway']) is list:\n",
    "            gdf_edges.loc[i, 'oneway'] = False\n",
    "    \n",
    "    edge_attrs = ['highway', 'oneway', 'length', 'bridge', 'lanes']\n",
    "    if 'bridge' in gdf_edges.columns:\n",
    "        gdf_edges['bridge'].fillna('nan', inplace=True)\n",
    "        for i in gdf_edges.index:\n",
    "            if type(gdf_edges.loc[i, 'bridge']) is list:\n",
    "                gdf_edges.loc[i, 'bridge'] = 'viaduct'\n",
    "        gdf_edges.loc[:, 'bridge'] = le.fit_transform(gdf_edges.loc[:, 'bridge'])\n",
    "    else:\n",
    "        edge_attrs.remove('bridge')\n",
    "        \n",
    "    if 'lanes' in gdf_edges.columns:\n",
    "        gdf_edges['lanes'].fillna('-1', inplace=True)\n",
    "        for i in gdf_edges.index:\n",
    "            lanes_val = gdf_edges.loc[i, 'lanes']\n",
    "            try:\n",
    "                if type(lanes_val) is list:\n",
    "                    lanes_val = [int(i) for i in lanes_val]\n",
    "                    gdf_edges.loc[i, 'lanes'] = str(int(np.mean(lanes_val)))\n",
    "            except:\n",
    "                gdf_edges.loc[i, 'lanes'] = gdf_edges.lanes.value_counts().index[0]\n",
    "        gdf_edges.loc[:, 'lanes'] = le.fit_transform(gdf_edges.loc[:, 'lanes'])\n",
    "    else:\n",
    "        edge_attrs.remove('lanes')\n",
    "        \n",
    "    gdf_edges = gdf_edges[edge_attrs]  \n",
    "    gdf_edges = pd.concat([gdf_edges, pd.get_dummies(gdf_edges.oneway, prefix='oneway')], axis=1)\n",
    "    gdf_edges = pd.concat([gdf_edges, pd.get_dummies(gdf_edges.highway, prefix='high')], axis=1)\n",
    "    \n",
    "    crash_time = gdf_nodes[['start_time', 'end_time']]\n",
    "    \n",
    "    # Some cities don't have the 'ref' feature\n",
    "    node_attrs_remove = ['ref', 'geometry', 'highway', 'start_time', 'end_time']\n",
    "    if 'ref' not in gdf_nodes.columns:\n",
    "        node_attrs_remove.remove('ref')\n",
    "    if 'highway' not in gdf_nodes.columns:\n",
    "        node_attrs_remove.remove('highway')\n",
    "    gdf_nodes.drop(node_attrs_remove, axis=1, inplace=True)\n",
    "\n",
    "    node_idx_map = {}\n",
    "    my_edge_index = []\n",
    "    node_ls = gdf_nodes.index.tolist()\n",
    "    for i, j in enumerate(node_ls):\n",
    "        node_idx_map[j] = i\n",
    "    for edge in gdf_edges.index:\n",
    "        my_edge_index.append((node_idx_map[edge[0]], node_idx_map[edge[1]]))\n",
    "    my_edge_attr = gdf_edges.drop(['highway', 'oneway'], axis=1)\n",
    "\n",
    "    labels = gdf_nodes.accident_cnt > 0  # for the occurrence prediction task only\n",
    "    labels = labels.astype(int)\n",
    "    features = gdf_nodes.drop(['accident_cnt', 'x', 'y', 'severity'], axis=1)\n",
    "    print(f'Node shape: {features.shape} features: {features.columns}')\n",
    "    print(f'Edge shape: {my_edge_attr.shape} features: {my_edge_attr.columns}')\n",
    "    \n",
    "    # print(labels.value_counts())\n",
    "    # print('Crash %:', round(100 * labels.values.sum() / len(labels.values)))\n",
    "    \n",
    "    # accident_percent = 100 * labels.sum() / labels.shape[0]\n",
    "    # x=features.values, occur_labels=labels.values, edge_attr=my_edge_attr.values"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "60cd8c30-abfa-411a-b9a0-b2c7e4963307"
   ],
   "name": "CS5242_group35.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env23jan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
